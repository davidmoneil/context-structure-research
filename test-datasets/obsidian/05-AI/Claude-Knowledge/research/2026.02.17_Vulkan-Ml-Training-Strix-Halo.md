---
type: claude-knowledge
source: aiprojects
source_path: ".claude/agent-output/results/deep-research/2026-02-17_vulkan-ml-training-strix-halo.md"
source_category: "deep-research"
synced: 2026-02-17
title: "Deep Research: Vulkan-Based ML Training on AMD Strix Halo"
tags:
  - claude-knowledge
  - deep-research
---

# Deep Research: Vulkan-Based ML Training on AMD Strix Halo

**Research Date**: 2026-02-17
**Confidence Level**: High (16+ sources consulted, cross-referenced)
**Sources Consulted**: 18 primary sources

---

## Executive Summary

Vulkan-based ML training is emerging but is NOT the practical path for training on AMD Strix Halo today. The landscape as of February 2026 breaks down as follows:

**For inference**: Vulkan is excellent on Strix Halo -- llama.cpp with Vulkan outperforms ROCm/HIP for prompt processing (884 t/s vs 349 t/s on Llama-2-7B) and works out of the box with no compilation required.

**For training/fine-tuning**: ROCm via TheRock (not stock ROCm) is the only practical path today. Community-built toolboxes exist specifically for Strix Halo fine-tuning using Unsloth + ROCm. The QVAC-fabric-llm project has demonstrated Vulkan-based LoRA training but it's experimental and not yet upstreamed.

**The best first test**: Use the `shantur/amd-strix-halo-fine-tuning-toolboxes` Docker image to run Unsloth-based LoRA fine-tuning of a 1-7B parameter model on ROCm. This is the most battle-tested path with documented results on the exact hardware.

---

## Key Findings

### 1. Framework Support for Vulkan ML Training

#### PyTorch Vulkan Backend -- NO TRAINING SUPPORT
- **Status**: The original PyTorch Vulkan backend is **unmaintained** as of 2025
- Development has shifted to **ExecuTorch Vulkan Delegate**, which is **inference-only**
- ExecuTorch targets Android/mobile deployment, not desktop training
- There is no official PyTorch training support via Vulkan. Period.
- A community issue (#160230) requesting official Vulkan backend on pytorch.org remains open

**Sources**: [PyTorch Vulkan Workflow Docs](https://docs.pytorch.org/tutorials/unstable/vulkan_workflow.html), [PyTorch Issue #160230](https://github.com/pytorch/pytorch/issues/160230), [PyTorch Forum - Vulkan Training](https://discuss.pytorch.org/t/vulkan-backend-training-and-mixed-half-precision/162816)

#### Kompute -- COMPUTE PRIMITIVES ONLY, NO ML TRAINING FRAMEWORK
- General-purpose Vulkan compute framework backed by the Linux Foundation
- Provides low-level GPU compute abstractions (tensors, sequences, operations)
- Has a logistic regression example, but no neural network training framework
- Useful as a building block, not a ready-to-use training solution
- Python and C++ APIs available
- Would require implementing your own training loop, optimizer, backprop from scratch

**Sources**: [Kompute GitHub](https://github.com/KomputeProject/kompute), [Kompute Docs](https://kompute.cc/), [Vulkan.org Blog on Kompute](https://www.vulkan.org/blog/beyond-cuda-gpu-accelerated-c-for-machine-learning-on-cross-vendor-graphics-cards-made-simple-with-kompute)

#### GGML/llama.cpp Vulkan -- TRAINING SUPPORT EMERGING (EXPERIMENTAL)
- **Inference**: Mature, production-quality Vulkan backend. Best performance on Strix Halo.
- **Training**: Active development of backward pass operators for Vulkan
  - `OUT_PROD` operator implemented for CUDA + Vulkan (int8, fp16) -- critical for LoRA
  - Backward pass support extended to float32, float16, int8, int4
  - GEGLU backward pass implemented (enables Gemma fine-tuning)
  - Masked cross-entropy loss implemented with Vulkan shaders
- **QVAC-fabric-llm**: The breakthrough project. First cross-platform LoRA fine-tuning solution using Vulkan as primary backend
  - Benchmarked: AMD 7900 XTX does Qwen3-1.7B Q8 LoRA in ~13 min/epoch
  - Supports instruction fine-tuning with masked loss
  - Dynamic tiling solves mobile GPU buffer limits
  - **NOT YET UPSTREAMED** to main llama.cpp -- available at `tetherto/qvac-fabric-llm.cpp`
  - Quality near-parity with PyTorch (79-94% biomedical accuracy vs 78-86%)

**Sources**: [QVAC-fabric-llm Blog](https://huggingface.co/blog/qvac/fabric-llm-finetune), [GGML Issue #1215](https://github.com/ggml-org/ggml/issues/1215), [GGML Vulkan Backend DeepWiki](https://deepwiki.com/ggml-org/ggml/3.3-vulkan-backend)

#### MLC-LLM -- INFERENCE ONLY
- Supports Vulkan as deployment backend for AMD/NVIDIA/Qualcomm
- No training or fine-tuning capability
- Useful for inference deployment, not relevant for training

**Sources**: [MLC-LLM GitHub](https://github.com/mlc-ai/mlc-llm), [MLC-LLM Docs](https://llm.mlc.ai/docs/get_started/introduction)

#### Custom Vulkan Compute Shaders -- TOY/RESEARCH STAGE
- **descent** (Rust): Toy library for neural networks via Vulkan compute shaders. Trains Fashion-MNIST.
- **VulkanShaderCUDA**: Demonstrates PyTorch-like tensor ops in GLSL shaders
- **VK_KHR_shader_bfloat16**: New Vulkan 1.4.311 extension enabling BF16 in shaders (NVIDIA beta)
- **VK_ARM_tensors/data_graph**: Arm extensions for native neural network execution
- None of these are practical for real ML training workloads today

**Sources**: [descent GitHub](https://github.com/sjb3d/descent), [VulkanShaderCUDA GitHub](https://github.com/waefrebeorn/VulkanShaderCUDA)

---

### 2. Vulkan vs ROCm for AMD GPUs -- Practical Comparison

#### For Inference (llama.cpp benchmarks on Strix Halo)

| Metric | Vulkan + FA | HIP + WMMA + FA | Winner |
|--------|------------|-----------------|--------|
| pp512 (Llama-2-7B) | 884.20 t/s | 343.91 t/s | **Vulkan (2.6x)** |
| tg128 (Llama-2-7B) | 52.73 t/s | 50.88 t/s | Vulkan (marginal) |
| pp8192 (extended) | 490.18 t/s | 368.77 t/s | **Vulkan (1.3x)** |
| tg8192 (extended) | 32.03 t/s | 50.97 t/s | **HIP (1.6x)** |
| Large models (109B) | Works | GPU hangs | **Vulkan** |

**Key insight**: Vulkan dominates prompt processing and stability on Strix Halo. HIP is better for extended generation at long contexts. For large models (>60GB), Vulkan may be the only option that doesn't hang.

#### For Training

| Aspect | Vulkan | ROCm (TheRock) |
|--------|--------|----------------|
| PyTorch training | Not supported | Working (with patches) |
| LoRA fine-tuning | Experimental (QVAC only) | Working (Unsloth) |
| Flash Attention | N/A for training | Available (16x speedup with AOTriton) |
| hipBLASLt | N/A | 36.9 TFLOPS (60% efficiency) |
| Community tooling | Minimal | Robust (Docker toolboxes) |
| Driver requirements | Mesa RADV (ships with distro) | AMDGPU DKMS + ROCm stack |
| Setup complexity | Low (for inference) | High (compilation, patches needed) |
| Multi-GPU training | No row-split support | Supported via ROCm |

**Bottom line**: ROCm is the only viable path for production training today. Vulkan training via QVAC-fabric-llm is promising but experimental.

#### Driver Maturity

- **RADV (Vulkan)**: Mature, ships with Mesa. RDNA 3.5 supported since Mesa 23.3. Mesa 26.0 brings further improvements. Works out of the box.
- **ROCm**: Stock ROCm 7.2 has poor gfx1151 performance. **TheRock 7.11+ nightlies are dramatically faster**. TheRock becomes ROCm 8.0 in March 2026. Community patches required for Flash Attention.
- **AMDGPU kernel driver**: Newer kernels (6.14+) recommended. Ubuntu 24.04 users need `amdgpu-install --usecase=dkms`.

#### Community Adoption

- Vulkan inference via llama.cpp: **High adoption**, active development, FOSDEM 2026 talk
- ROCm training: **Growing community**, dedicated Strix Halo toolbox repos, Framework community guides
- Vulkan training: **Very early**, mostly QVAC research team

**Sources**: [Phoronix ROCm 7 Strix Halo](https://www.phoronix.com/review/amd-rocm-7-strix-halo), [llm-tracker Strix Halo](https://llm-tracker.info/AMD-Strix-Halo-(Ryzen-AI-Max+-395)-GPU-Performance), [Phoronix ROCm 7.1 vs RADV Vulkan](https://www.phoronix.com/review/rocm-71-llama-cpp-vulkan), [FOSDEM 2026 Vulkan ML Talk](https://fosdem.org/2026/schedule/event/CZSPSC-llama-cpp-vulkan/)

---

### 3. AMD Strix Halo (Ryzen AI Max+ 395) Compatibility

#### Hardware Specifications
- **GPU**: Radeon 8060S, RDNA 3.5 architecture, 40 CUs, gfx1151
- **Peak Compute**: 59.4 FP16/BF16 TFLOPS at 2.9GHz
- **Memory Bandwidth**: 212 GB/s measured (256 GB/s theoretical)
- **Unified Memory**: Up to 96GB VRAM (from 128GB system total)
- **CPU-GPU Transfer**: ~84 GB/s

#### Vulkan Compute Status
- **Works out of the box** via Mesa RADV driver on modern Linux (Mesa 23.3+)
- llama.cpp Vulkan inference tested and performant
- No known RDNA 3.5-specific Vulkan compute bugs
- Vulkan 1.3+ supported

#### Known Issues with RDNA 3.5 and Compute
1. **ROCm gfx1151 not officially supported** in stock ROCm 7.2 (works but undocumented)
2. **Flash Attention**: Requires custom AOTriton compilation for gfx1151 (~1 hour build)
3. **hipBLASLt**: Requires manual compilation from source for gfx1151
4. **MIOpen**: Conv2d failures require patches (disabled AI_KERNEL_TUNING, disabled wino_fury solver)
5. **Training performance**: ~1 TFLOPS without hipBLASLt; 36.9 TFLOPS with it (critical dependency)
6. **Memory overhead**: Some models consume 3x expected VRAM due to disabled MIOpen kernels
7. **Random segfaults**: Reported on Ubuntu with older kernel drivers
8. **Gemma-3 NaN loss on Unsloth**: Caused by `torch.compile` on HIP; fix: disable compile for Gemma3

#### What Works Well
- Vulkan inference (best-in-class for Strix Halo)
- ROCm inference and training (with TheRock + community patches)
- Models up to 109B parameters for inference (with quantization)
- LoRA fine-tuning up to 12B full, 20-30B with quantization
- Stable Diffusion, ComfyUI, vLLM (with patches)

**Sources**: [Framework Community Strix Halo](https://community.frame.work/t/amd-strix-halo-ryzen-ai-max-395-gpu-llm-performance-tests/72521), [Level1Techs Forum](https://forum.level1techs.com/t/strix-halo-ryzen-ai-max-395-llm-benchmark-results/233796), [TheRock Discussion #244](https://github.com/ROCm/TheRock/discussions/244), [Framework Linux ROCm Jan 2026](https://community.frame.work/t/linux-rocm-january-2026-stable-configurations-update/79876)

---

### 4. Best First Test: Recommended Approach

#### Option A: Quickest Path (ROCm + Unsloth Toolbox) -- RECOMMENDED

This is the most battle-tested approach with documented results on Strix Halo.

**Setup**:
```bash
# 1. Install udev rules for GPU access (one-time)
sudo tee /etc/udev/rules.d/99-amd-kfd.rules <<'EOF'
KERNEL=="kfd", MODE="0666"
SUBSYSTEM=="drm", KERNEL=="renderD*", MODE="0666"
EOF
sudo udevadm control --reload-rules && sudo udevadm trigger

# 2. Pull the fine-tuning toolbox
toolbox create toolbox-all --image docker.io/shantur/amd-strix-halo-fine-tuning-toolboxes
# OR use Docker:
docker pull shantur/amd-strix-halo-fine-tuning-toolboxes

# 3. Run the container with GPU access
docker run -it --device=/dev/kfd --device=/dev/dri \
  --group-add video --group-add render \
  -v $(pwd)/data:/data \
  shantur/amd-strix-halo-fine-tuning-toolboxes

# 4. Inside container: Fine-tune a small model (Gemma-3-1B)
# The toolbox includes Unsloth and training scripts
# Full fine-tune of Gemma-3-1B: ~19GB memory, ~3 minutes
# LoRA fine-tune: ~15GB memory, ~2 minutes
```

**Expected Results (Gemma-3-1B, 2 epochs)**:
| Method | Memory | Time |
|--------|--------|------|
| Full fine-tune | 19.43 GB | ~3 min |
| LoRA | 15.40 GB | ~2 min |
| 8-bit + LoRA | 13.06 GB | ~11 min |
| QLoRA | 13.08 GB | ~3 min |

**Model size guidance for 96GB unified memory**:
- Full fine-tune: Up to 12B parameters
- LoRA: Up to 20-30B parameters (with quantization)
- Inference: Up to 109B parameters (with quantization)

#### Option B: Vulkan Training (Experimental)

If you specifically want to validate Vulkan-based training:

```bash
# 1. Clone the QVAC fork of llama.cpp with fine-tuning support
git clone https://github.com/tetherto/qvac-fabric-llm.cpp.git
cd qvac-fabric-llm.cpp
git checkout fabric-llm-finetune

# 2. Build with Vulkan backend
cmake -B build -DGGML_VULKAN=ON
cmake --build build --config Release -j$(nproc)

# 3. Download a small model (Qwen3-1.7B Q8)
# (Use huggingface-cli or manual download)

# 4. Run LoRA fine-tuning
./build/bin/llama-finetune-lora \
    -m Qwen3-1.7B-Q8_0.gguf \
    -f training-data.jsonl \
    --assistant-loss-only \
    --lora-rank 16 \
    --lora-alpha 32 \
    -c 512 -b 128 -ub 128 \
    -ngl 999 -fa off
```

**Caveat**: This is from the QVAC research team's fork, not upstream llama.cpp. It works but is experimental.

#### Option C: PyTorch Training via TheRock (Most Flexible)

For the most flexible training setup with PyTorch:

```bash
# 1. Pull the TheRock PyTorch container for gfx1151
podman pull docker.io/scottt/therock:pytorch-vision-dev-f41

# 2. Run with GPU access
podman run -it --device=/dev/kfd --device=/dev/dri \
  --group-add video \
  scottt/therock:pytorch-vision-dev-f41

# 3. Verify GPU detection
python3 -c "import torch; print(torch.cuda.is_available()); print(torch.cuda.get_device_name(0))"

# 4. Run a simple training validation
python3 -c "
import torch
x = torch.randn(1000, 1000, device='cuda')
y = torch.randn(1000, 1000, device='cuda')
z = torch.mm(x, y)
print(f'Matrix multiply on GPU: {z.shape}')
# Simple gradient test
w = torch.randn(100, 100, device='cuda', requires_grad=True)
loss = (w @ w.T).sum()
loss.backward()
print(f'Backward pass works: grad shape = {w.grad.shape}')
"
```

**Note**: For Flash Attention (16x speedup), you need custom PyTorch builds with AOTriton compiled for gfx1151. See the [strix-halo-testing repo](https://community.frame.work/t/pytorch-w-flash-attention-vllm-for-strix-halo/74736).

---

### 5. Alternatives to Consider

#### ROCm via TheRock (RECOMMENDED for training)
- **Status**: Working, actively improving
- TheRock 7.11 nightlies dramatically outperform stock ROCm 7.2 on gfx1151
- TheRock becomes ROCm 8.0 in March 2026
- Community has solved most critical issues (Flash Attention, hipBLASLt)
- Best path: Wait for ROCm 8.0 (March 2026) for official gfx1151 support

#### HIP (Part of ROCm)
- HIP is ROCm's CUDA-compatible programming model
- All ROCm training goes through HIP
- Not a separate alternative; it's the underlying API for ROCm training

#### OpenCL
- Legacy, not recommended for ML training
- No modern framework support
- Vulkan compute has superseded OpenCL for new development

#### Fine-Tuning vs Training from Scratch

| Approach | Framework Requirements | Strix Halo Feasibility |
|----------|----------------------|----------------------|
| LoRA fine-tuning | Unsloth + ROCm (working) | Excellent -- 20-30B models |
| QLoRA fine-tuning | Unsloth + ROCm (working) | Excellent -- similar memory, slightly slower |
| Full fine-tuning | PyTorch + ROCm (working) | Good -- up to 12B models |
| Training from scratch | PyTorch + ROCm (partial) | Limited -- Flash Attention critical, slow without it |
| Vulkan LoRA | QVAC-fabric-llm (experimental) | Possible but experimental |

**Recommendation**: Start with LoRA fine-tuning via Unsloth + ROCm. This is the most proven path. If you need Vulkan specifically (e.g., for portability or avoiding ROCm complexity), the QVAC-fabric-llm project is the most advanced option but requires building from source.

---

## Detailed Analysis

### The Unified Memory Advantage

The 96GB unified memory pool on Strix Halo is its killer feature for ML. Here's how it compares:

| GPU | VRAM | Bandwidth | Training Ceiling |
|-----|------|-----------|-----------------|
| RTX 4090 | 24GB | 1,008 GB/s | ~7B full, ~13B LoRA |
| RTX 5090 | 32GB | 1,792 GB/s | ~10B full, ~20B LoRA |
| Strix Halo (96GB) | 96GB unified | 212 GB/s | ~12B full, ~30B LoRA |
| M4 Max (128GB) | 128GB unified | 546 GB/s | ~20B full, ~40B LoRA |

Strix Halo trades bandwidth for capacity. You can load larger models but processing is slower. For fine-tuning (which is memory-bound more than compute-bound), this tradeoff is favorable.

### The Software Stack Maturity Problem

The fundamental challenge is that AMD's software stack for RDNA 3.5 is immature:

1. **gfx1151 not officially on ROCm support matrix** -- everything relies on community patches
2. **Flash Attention requires manual AOTriton builds** -- without it, training is ~16x slower
3. **hipBLASLt requires source builds** -- without it, matrix multiply is at 9% efficiency instead of 60%
4. **TheRock vs ROCm confusion** -- TheRock 7.11 works much better than ROCm 7.2 but the naming/relationship is confusing
5. **March 2026 inflection point** -- TheRock becomes ROCm 8.0, which should bring official gfx1151 support

### Vulkan Training: Where It's Headed

The FOSDEM 2026 talk "Vulkan API for Machine Learning? Competing with CUDA and ROCm in llama.cpp" by Ruben Ortlam explicitly addresses Vulkan as an ML backend. Key signals:

1. QVAC-fabric-llm has proven Vulkan LoRA training works (quality parity with PyTorch)
2. GGML backward pass operators are being implemented for Vulkan
3. VK_KHR_shader_bfloat16 extension enables BF16 in Vulkan shaders
4. Dynamic tiling solves buffer size constraints on resource-limited GPUs

But Vulkan training is 12-18 months behind ROCm for practical use. The path forward is:
- H1 2026: QVAC contributions upstreamed to llama.cpp
- H2 2026: Vulkan LoRA fine-tuning becomes mainstream in llama.cpp
- 2027+: Broader framework adoption (if PyTorch ever adds Vulkan training)

---

## Best Practices

1. **Start with inference validation**: Confirm Vulkan compute works on your hardware with `llama.cpp -ngl 999 --vulkan`
2. **Use Docker/toolbox containers**: Avoid polluting your system with ROCm dependencies
3. **Build from TheRock, not stock ROCm**: TheRock 7.11+ has dramatically better gfx1151 support
4. **Set UMA VRAM to maximum in BIOS**: Usually 96GB on 128GB systems
5. **Use kernel 6.14+**: Older kernels have gfx1151 stability issues
6. **Monitor with `rocm-smi`**: Verify GPU utilization during training
7. **Start small**: Validate with 1B model before scaling to 7B+ models
8. **Check `/dev/kfd` permissions**: Most common setup issue on Linux

---

## Common Pitfalls

1. **Assuming Vulkan can do training today** -- It cannot (outside of experimental QVAC fork)
2. **Using stock ROCm 7.2** -- Use TheRock 7.11+ nightlies instead
3. **Skipping hipBLASLt** -- Without it, matrix multiply runs at 9% efficiency
4. **Not compiling AOTriton for gfx1151** -- Flash Attention gives 16x training speedup
5. **Using `torch.compile` with Gemma-3 on ROCm** -- Causes NaN losses; disable it
6. **Expecting NVIDIA-level "just works" experience** -- Budget 2-4 hours for initial setup
7. **Running bitsandbytes on AMD** -- Disabled in Unsloth for AMD; use 16-bit LoRA instead

---

## Conflicting Information

1. **Vulkan vs ROCm for Strix Halo inference**: Some sources say Vulkan is always better; benchmarks show HIP+WMMA+FA is better for long-context generation (tg8192). Both have strengths depending on workload.

2. **Training performance claims**: The llm-tracker page reports ~1 TFLOPS training performance (very bad), but this is WITHOUT hipBLASLt. With hipBLASLt the same hardware does 36.9 TFLOPS. Context matters enormously.

3. **ROCm 7.2 vs TheRock**: Some guides reference ROCm 7.2 as working; community consensus is that TheRock nightlies work significantly better. The naming transition (TheRock -> ROCm 8.0 in March 2026) adds confusion.

4. **Gemma-3 training**: Works with Qwen/Llama models but hits NaN issues with Gemma-3 specifically on ROCm. The fix (disabling torch.compile) is available but not widely documented.

---

## Knowledge Gaps

1. **QVAC-fabric-llm on Strix Halo specifically** -- Benchmarks exist for 7900 XTX but not gfx1151
2. **Vulkan training power consumption vs ROCm** -- No comparative data available
3. **Long-running training stability on Strix Halo** -- Most reports are short experiments, not multi-hour training runs
4. **ROCm 8.0 official gfx1151 support details** -- Expected March 2026 but no specifics confirmed
5. **Multi-model training throughput** -- No data on running multiple training jobs concurrently

---

## Recommendations

### Immediate (this week)
1. Set up the Strix Halo fine-tuning toolbox container
2. Run LoRA fine-tuning on Gemma-3-1B (or Qwen-3-1.7B if Gemma hits issues) to validate the hardware
3. Measure actual memory usage and training throughput

### Short-term (next month)
1. Build custom PyTorch with AOTriton for gfx1151 to enable Flash Attention
2. Scale to 7B-12B model fine-tuning
3. Test QVAC-fabric-llm fork for Vulkan-native training

### Medium-term (Q2 2026)
1. Migrate to ROCm 8.0 (formerly TheRock) when it ships in March 2026
2. Evaluate upstreamed Vulkan training support in llama.cpp
3. Consider full 20-30B LoRA fine-tuning once the stack stabilizes

---

## Sources

1. [FOSDEM 2026 - Vulkan API for ML in llama.cpp](https://fosdem.org/2026/schedule/event/CZSPSC-llama-cpp-vulkan/) - High credibility (conference talk)
2. [llm-tracker: Strix Halo GPU Performance](https://llm-tracker.info/AMD-Strix-Halo-(Ryzen-AI-Max+-395)-GPU-Performance) - High credibility (community benchmark aggregator)
3. [Phoronix: ROCm 7 on Strix Halo](https://www.phoronix.com/review/amd-rocm-7-strix-halo) - High credibility (established tech publication)
4. [QVAC-fabric-llm: Edge-First LoRA Fine-Tuning](https://huggingface.co/blog/qvac/fabric-llm-finetune) - High credibility (HuggingFace blog, includes benchmarks)
5. [Framework Community: Fine-tuning LLMs on Strix Halo](https://community.frame.work/t/finetuning-llms-on-strix-halo-full-lora-and-qlora-on-gemma-3-qwen-3-and-gpt-oss-20b/76986) - High credibility (first-party hardware community)
6. [Framework Community: PyTorch Flash Attention on Strix Halo](https://community.frame.work/t/pytorch-w-flash-attention-vllm-for-strix-halo/74736) - High credibility
7. [ROCm/TheRock Discussion #244: PyTorch on gfx1151](https://github.com/ROCm/TheRock/discussions/244) - High credibility (official ROCm repo)
8. [ROCm/TheRock Discussion #655: Strix Halo PyTorch Wheels](https://github.com/ROCm/TheRock/discussions/655) - High credibility
9. [Strix Halo Fine-Tuning Toolboxes](https://github.com/shantur/amd-strix-halo-fine-tuning-toolboxes) - Medium credibility (community project)
10. [Strix Halo Toolboxes (kyuz0)](https://github.com/kyuz0/amd-strix-halo-toolboxes) - Medium credibility
11. [Unsloth AMD Install Docs](https://unsloth.ai/docs/get-started/install/amd) - High credibility (official docs)
12. [Unsloth Issue #3385: NaN Loss on gfx1151](https://github.com/unslothai/unsloth/issues/3385) - High credibility (bug tracker)
13. [Kompute GitHub Repository](https://github.com/KomputeProject/kompute) - High credibility
14. [PyTorch Vulkan Workflow Docs](https://docs.pytorch.org/tutorials/unstable/vulkan_workflow.html) - High credibility (official)
15. [Level1Techs: Strix Halo LLM Benchmarks](https://forum.level1techs.com/t/strix-halo-ryzen-ai-max-395-llm-benchmark-results/233796) - High credibility
16. [Phoronix: ROCm 7.1 vs RADV Vulkan for llama.cpp](https://www.phoronix.com/review/rocm-71-llama-cpp-vulkan) - High credibility
17. [ROCm 7.2.0 Release Notes](https://rocm.docs.amd.com/en/latest/about/release-notes.html) - High credibility (official)
18. [Framework Community: Linux ROCm Jan 2026 Stable Configs](https://community.frame.work/t/linux-rocm-january-2026-stable-configurations-update/79876) - High credibility

---

## Related Topics

- ROCm 8.0 (TheRock transition) -- expected March 2026
- AMD XDNA NPU utilization on Strix Halo for inference offload
- Vulkan cooperative matrix extensions for ML (VK_KHR_cooperative_matrix)
- llama.cpp upstream training integration timeline
- Comparison with Apple M4 Max unified memory training performance
