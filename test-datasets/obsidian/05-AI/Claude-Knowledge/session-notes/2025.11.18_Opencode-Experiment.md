---
type: claude-knowledge
source: aiprojects
source_path: "knowledge/notes/session-20251118-opencode-experiment.md"
source_category: "session-knowledge"
synced: 2026-02-17
title: "OpenCode Experimentation"
tags:
  - claude-knowledge
  - session-knowledge
---

# OpenCode Experimentation

**Status:** Testing (not production)
**Start Date:** 2025-11-18
**Goal:** Evaluate cost savings with local models vs Claude API
**Decision Deadline:** TBD (after 1-2 weeks of testing)

## Installation Summary

- **OpenCode Version:** 1.0.72
- **Install Date:** 2025-11-18
- **Install Method:** curl -fsSL https://opencode.ai/install | bash
- **Binary Location:** `/home/davidmoneil/.opencode/bin/opencode`
- **Config Location:** `~/AIProjects/opencode.json`

## Configuration

### Current Setup (Minimal - Testing Phase)

```json
{
  "providers": {
    "ollama": {
      "baseURL": "http://localhost:11434/v1"
    }
  },
  "defaultModel": "ollama:qwen2.5:7b-instruct"
}
```

**Available Local Models:**
- `qwen2.5:7b-instruct` (4.7 GB) - Primary testing model
- `llama2:latest` (3.8 GB) - Backup/comparison
- `nomic-embed-text:latest` (274 MB) - Embeddings

**Claude API:** Not yet configured (will add after basic testing)

**MCP Servers:** Not migrated (keeping Claude Code as production)

## Testing Plan

### Phase 1: Basic Functionality (Week 1)
- [ ] Test simple code generation with Qwen 2.5
- [ ] Compare output quality vs Claude Sonnet 4.5
- [ ] Test response speed (local vs API)
- [ ] Evaluate context retention across conversations
- [ ] Test file reading/editing capabilities

### Phase 2: Model Comparison (Week 2)
- [ ] Add Claude API to OpenCode config
- [ ] Same task with different models (side-by-side)
- [ ] Document quality differences
- [ ] Track actual cost savings
- [ ] Test model switching mid-conversation

### Phase 3: Decision Point (Week 3)
- [ ] Review findings
- [ ] Calculate ROI (cost savings vs quality tradeoff)
- [ ] Decide: Adopt, Hybrid, or Remove
- [ ] If adopting: Plan MCP migration
- [ ] If removing: Execute cleanup script

## Files Created (for easy cleanup)

```bash
# Configuration
~/AIProjects/opencode.json              # Main config

# Binary & cache
~/.opencode/bin/opencode                # Binary location
~/.opencode/                            # Session data (if created)

# Project files (if created during testing)
~/AIProjects/AGENTS.md                  # Codebase analysis (optional)
~/AIProjects/.opencode/                 # Project-specific session data

# Documentation
knowledge/notes/session-20251118-opencode-experiment.md  # This file

# .gitignore entries
# (Added to prevent accidental commits during testing)
```

## Removal Instructions

If we decide not to adopt OpenCode after testing:

```bash
# 1. Remove OpenCode config and project files
cd ~/AIProjects
rm -f opencode.json AGENTS.md
rm -rf .opencode/

# 2. Remove the binary installation
rm -rf ~/.opencode/

# 3. Remove PATH export from .bashrc
# Edit ~/.bashrc and remove these lines:
#   # opencode
#   export PATH=/home/davidmoneil/.opencode/bin:$PATH

# 4. Clean .gitignore
# Edit .gitignore and remove:
#   # OpenCode experimentation (temporary - remove if adopting OpenCode)
#   opencode.json
#   AGENTS.md
#   .opencode/

# 5. Delete experiment notes (optional)
rm knowledge/notes/session-20251118-opencode-experiment.md

# 6. Reload shell
source ~/.bashrc

# Done! Zero traces left.
```

## Testing Notes

### Test 1: Installation & Setup
- ✅ OpenCode 1.0.72 installed successfully
- ✅ Config created with Ollama integration
- ✅ Files added to .gitignore (isolated experimentation)
- ⏳ Next: Run basic test query

### Test 2: [TBD]


## Comparison: OpenCode vs Claude Code

| Feature | OpenCode | Claude Code | Notes |
|---------|----------|-------------|-------|
| **Cost** | Free (local) | $$$ (API) | Major advantage for OpenCode |
| **Quality** | ? | Excellent | Testing needed |
| **Speed** | ? (local) | Fast (API) | Testing needed |
| **MCP Support** | Yes | Yes | Both support MCP |
| **Multi-model** | Yes | No | OpenCode advantage |
| **Workflows** | None yet | Established | Claude Code advantage |
| **Documentation** | None | Extensive | Claude Code advantage |

## Decision Criteria

**Adopt OpenCode if:**
- Quality is 80%+ of Claude for routine tasks
- Cost savings are >60%
- Local models handle most day-to-day work
- Can establish clear model selection guidelines

**Keep Claude Code if:**
- Quality difference is too significant
- Local model performance is inconsistent
- Workflow migration effort isn't worth savings
- MCP integration is problematic

**Hybrid Approach if:**
- Both tools excel at different tasks
- Cost savings justify maintaining two systems
- Clear task categorization is possible

## Next Session TODO

- [ ] Run first test query with OpenCode
- [ ] Document first impressions
- [ ] Add Claude API to config (after basic test)
- [ ] Create simple test script for comparisons

## Questions to Answer

1. How does Qwen 2.5 7B compare to Claude Sonnet 4.5 for typical coding tasks?
2. What's the actual cost savings over a week of normal use?
3. Does model switching mid-conversation work smoothly?
4. Are there tasks where local models clearly fall short?
5. Is the quality tradeoff worth the cost savings?
6. Can we establish clear "use this model for X" guidelines?

## Resources

- OpenCode Docs: https://opencode.ai/docs
- OpenCode Providers: https://opencode.ai/docs/providers
- OpenCode MCP: https://opencode.ai/docs/mcp-servers
- This Project's Claude Code Docs: `.claude/context/_index.md`
